<!DOCTYPE html>
<html>
  <head>
    <title>MediaPipe Pose/Stroke Analysis</title>

    <!-- post detection model -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose"
      onload="window.ReactNativeWebView.postMessage('Pose loaded');"
      onerror="window.ReactNativeWebView.postMessage('Pose failed to load');">
    </script>
    <!-- drawing landmarks and connections -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils"
      onload="window.ReactNativeWebView.postMessage('Drawing utils loaded');"
      onerror="window.ReactNativeWebView.postMessage('Drawing utils failed to load');">
    </script>
    <!-- camera input -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"
      onload="window.ReactNativeWebView.postMessage('Camera utils loaded');"
      onerror="window.ReactNativeWebView.postMessage('Camera utils failed to load');">
    </script>
    <style>
      html, body {
        height: 100%;
        margin: 0;
        padding: 0;
        /* allows for scrolling */
        overflow: auto;
        /* smoother scrolling in iOS */
        -webkit-overflow-scrolling: touch; 
      }
      video {
        width: 100%;
        height: auto;
      }
      canvas {
        width: 100%;
        height: auto;
        display: block;
      }
    </style>
  </head>
  <body>
    <h1 style="color: red; text-align: center;">HTML is Loaded and Visible!</h1>

    <!-- video component that loads and plays the video passed from React Native Expo -->
    <video id="input_vid" controls playsinline
      onerror="window.ReactNativeWebView.postMessage('Video error: ' + event.target.error.code)"
      onloadeddata="window.ReactNativeWebView.postMessage('Video loaded')"
      onplaying="window.ReactNativeWebView.postMessage('Video playing')">
    </video>
    
    <!-- draws pose landmarks over video -->
    <canvas id="output_canvas"></canvas>

    <script>
      let vid = document.getElementById("input_vid");
      let canvas = document.getElementById("output_canvas");
      let canvas_context = canvas.getContext('2d');

      let pose;
      //tracks results (individual frames)
      let poseFrames = [];

      //function that normalizes landmarks relative to the hips
      function normalize(landmarks) {
        //grabs hip landmarks from MediaPipe
        const leftHip = landmarks[23];
        const rightHip = landmarks[24];

        //calculates the midpoint between the hips (in both the x, y, z direction)
        //acts as the new origin for the body
        const midpointX = (leftHip.x + rightHip.x) / 2;
        const midpointY = (leftHip.y + rightHip.y) / 2;
        const midpointZ = (leftHip.z + rightHip.z) / 2;

        //calculates distance between the hips
        //allows for size of individual to no longer matter; allows for focus on pose/shape
        const scale = Math.sqrt(
          Math.pow(leftHip.x - rightHip.x, 2) +
          Math.pow(leftHip.y - rightHip.y, 2) +
          Math.pow(leftHip.z - rightHip.z, 2)
        );

        return landmarks.map(landmark => ({
          //subtract midpoint to move origin to the hips
          //divide by scale to normalize for body size
          x: (landmark.x - midpointX) / scale,
          y: (landmark.y - midpointY) / scale,
          //z and visibility are unchanged
          z: (landmark.z - midpointZ) / scale,
          visibility: landmark.visibility
        }));
      }

      //function that calculates the angle between three points
      function calculateAngle(a, b, c) {
        //create vectors
        const u = {
          x: a.x - b.x,
          y: a.y - b.y,
          z: a.z - b.z
        };
        const v = {
          x: c.x - b.x,
          y: c.y - b.y,
          z: c.z - b.z,
        };

        //cos(theta) = dot product / product of magnitudes

        //dot product
        const dot = (u.x * v.x) + (u.y * v.y) + (u.z * v.z);

        //calculating the magnitudes
        const mag_u = Math.sqrt(u.x * u.x + u.y * u.y + u.z * u.z);
        const mag_v = Math.sqrt(v.x * v.x + v.y * v.y + v.z * v.z);

        if (mag_u === 0 || mag_v === 0) {
          return 0;
        }

        const cosAngle = Math.min(Math.max(dot / (mag_u * mag_v), -1), 1);

        //take arccos for the angle
        //returns angle in degrees
        return Math.acos(cosAngle) * (180 / Math.PI);
      }

      //function for phase detection
      function detectPhase(landmarks) {
        //right side landmarks
        const wristR = landmarks[16]; // right wrist
        const elbowR = landmarks[14]; // right elbow
        const shoulderR = landmarks[12]; //right shoulder
        const hipR = landmarks[24]; //right hip
        const kneeR = landmarks[26]; //right knee
        const ankleR = landmarks[28] //right ankle

        //left side landmarks
        const wristL = landmarks[15]; //left wrist
        const elbowL = landmarks[13]; // left elbow
        const shoulderL = landmarks[11]; //left shoulder
        const hipL = landmarks[23]; //left hip
        const kneeL = landmarks[25]; //left knee
        const ankleL = landmarks[27] //left ankle

        //right side angles
        const elbowAngleR = calculateAngle(shoulderR, elbowR, wristR);
        const shoulderAngleR = calculateAngle(elbowR, shoulderR, hipR);
        const kneeAngleR = calculateAngle(hipR, kneeR, ankleR);

        //left side angles
        const elbowAngleL = calculateAngle(shoulderL, elbowL, wristL);
        const shoulderAngleL = calculateAngle(elbowL, shoulderL, hipL);
        const kneeAngleL = calculateAngle(hipL, kneeL, ankleL);

        if (
          ((wristR.visibility < 0.75) || (wristR.z > shoulderR.z)) &&      //right wrist not visible or wrist in front of shoulders
          (shoulderL.z < shoulderR.z - 0.10)                               //slight tilt in torso
        ) {
          return "Follow-Through";
        }

        if (
          wristR.visibility > 0.5 &&
          (wristR.y > (hipR.y + 30)) &&        // wrist below hip
          wristR.z < elbowR.z &&                       // wrist closer than elbow 
          wristL.z > wristR.z && elbowL.z > wristR.z   // left arm further than right wrist
        ) {
          return "Acceleration";
        }

        if (
          wristR.visibility > 0.5 &&
          (wristR.y <= elbowR.y) &&                   // wrist above elbow
          (wristR.y < hipR.y && elbowR.y < hipR.y) && // wrist and elbow above hip
          (ankleL.z > ankleR.z) &&                   // left foot further from camera
          (shoulderL.z > shoulderR.z) &&             // left shoulder further from camera
          (elbowR.z < hipR.z)                        // arm behind hip
        ) {
          return "Preparation";
        }

        if ((wristR.visibility < 0.5 && wristL.visibility < 0.5) && //wrists not visible
            (kneeAngleL < 175 && kneeAngleR < 175)) {               //knees slightly bent
          return "Ready Position";
        }

        return "Unknown"; 
      }

      window.handleVideoUri = function(video_uri) { //function takes uri sent by React Native
        window.ReactNativeWebView.postMessage("Handling video URI: " + video_uri);
        vid.src = video_uri;

        //creates MediaPipe pose instance
        pose = new window.Pose({
          locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`
        });
        pose.setOptions({
          modelComplexity: 1,
          smoothLandmarks: true,
          enableSegmentation: false,
          minDetectionConfidence: 0.5,
          minTrackingConfidence: 0.5
        });

        //draws landmarks and connectors
        pose.onResults(results => {
          //sets canvas size
          if (canvas.width !== vid.videoWidth || canvas.height !== vid.videoHeight) {
            canvas.width = vid.videoWidth;
            canvas.height = vid.videoHeight;
          }

          //saves canvas state
          canvas_context.save();
          //clears any previous drawings
          canvas_context.clearRect(0, 0, canvas.width, canvas.height);
          //draws the current video frame with results from MediaPipe (results.image) onto the canvas
          canvas_context.drawImage(results.image, 0, 0, canvas.width, canvas.height);

          if (results.poseLandmarks) {

            //calls functions created above
            const norm = normalize(results.poseLandmarks);
            const phase = detectPhase(norm);

            poseFrames.push({
              timestamp: vid.currentTime, phase, //records timestamp and phase
              landmarks: norm //adds normalized landmark

              //landmarks: JSON.parse(JSON.stringify(results.poseLandmarks)), // deep copy of landmark
            });

            //takes landmarks pairs (either through POSE_CONNECTIONS or manually set up pairs)
            const POSE_CONNECTIONS = window.Pose?.POSE_CONNECTIONS || [
              [0,1],[1,2],[2,3],[3,7],
              [0,4],[4,5],[5,6],[6,8],
              [9,10],[11,12],
              [11,13],[13,15],[15,17],[15,19],[15,21],
              [17,19],[12,14],[14,16],[16,18],[16,20],[16,22],
              [18,20],[23,24],
              [11,23], [12,24],
              [23,25],[24,26],[25,27],[26,28],
              [27,29],[28,30],[29,31],[30,32]
            ];

            //draws the connectors (lines)
            drawConnectors(canvas_context, results.poseLandmarks, POSE_CONNECTIONS, {
              color: '#FF0000',
              lineWidth: 2,
            });
            //draws the landmarks (points)
            drawLandmarks(canvas_context, results.poseLandmarks, {
              color: '#FF0000',
              lineWidth: 1,
              circleRadius: 3,
            });

            //display phase classification on canvas
            canvas_context.font = "bold 100px Arial";
            canvas_context.fillStyle = 'yellow';
            canvas_context.fillText(`Phase: ${phase}`, 20, 50);

            //sends phase to React Native
            window.ReactNativeWebView.postMessage(JSON.stringify({
              time: vid.currentTime,
              phase: phase
            }));
          }
          //restores the canvas state after drawing
          canvas_context.restore();
        });

        // sends video frames to pose after video plays
        vid.onplay = () => {
          window.ReactNativeWebView.postMessage("Video playing, starting pose processing.");
          //starts loop by calling onVideoFrame function each frame
          requestAnimationFrame(onVideoFrame);
        };

        function onVideoFrame() {
          //if video is ready and playing
          if (vid.readyState >= 2 && !vid.paused && !vid.ended) {
            //sends video frame to pose model for processing
            pose.send({image: vid});
          }
          //continues loop by requesting next frame
          requestAnimationFrame(onVideoFrame);
        }
      };

      window.onload = function() {
        window.ReactNativeWebView.postMessage('pageReady');
        if (window.Pose) {
          window.ReactNativeWebView.postMessage('Pose is available');
        } else {
          window.ReactNativeWebView.postMessage('Pose is not available');
        }
      };

    </script>
  </body>
</html>
