<!DOCTYPE html>
<html>
  <head>
    <title>MediaPipe Pose/Stroke Analysis</title>

    <!-- post detection model -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose"></script>
    <!-- drawing landmarks and connections -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils"></script>
    <!-- camera input -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
    
    <style>
      video,canvas {
        width: 100%;
        height: auto;
      }
    </style>
  </head>
  <body>
    <!-- video element to play video -->
    <video id="input_vid" controls playsinline></video>
    <!-- canvas for drawing landmarks  -->
    <canvas id="output_canvas"></canvas>

    <script>
      let vid = document.getElementById("input_video");
      let canvas = document.getElementById("output_canvas");
      //preparing canvas 2D context
      let canvas_context = canvas.getContext('2d');

      //listens for a message from React Native WebView
      window.document.addEventListener('message', function(event) {

        //obtains video URI sent from React Native
        const video_uri = event.data;

        vid.src = video_uri;
        //start playback
        vid.play();

        //MediaPipe Pose Setup
        let pose = new Pose.pose({
          locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`
        });

        pose.setOptions({
          modelComplexity: 1,
          // applies smoothing filters to reduce jitter
          smoothLandmarks: true,
          //segmentation masks aren't generated (improves performance)
          enableSegmentation: false,
          //default confidence levels
          minDetectionConfidence: 0.5,
          minTrackingConfidence: 0.5
        });

        //sets up a callback that runs every time a fram is processed
        pose.onResults(results => {
          //saves current drawing state of the canvas (to restore later)
          canvas_context.save();
          //clears the canvas
          canvas_context.clearRect(0,0, canvas.width, canvas.height);
          //draws the current video fram onto the canvas
          canvas_context.drawImage(results.image, 0, 0, canvas.width, canvas.height);
          //draws lines and pose markings if body landmarks are detected
          if (results.poseLandmarks) {
            drawConnectors(canvasCtx, results.poseLandmarks, Pose.POSE_CONNECTIONS,
                         {color: '#00FF00', lineWidth: 4});
            drawLandmarks(canvasCtx, results.poseLandmarks, {color: '#FF0000', lineWidth: 2});
          }
          //restores the canvas to its previous drawing state
          canvas_context.restore();
        })

        //callback that runs when the video loads enough data to start playing
        videoElement.addEventListener('loadeddata', () => {
          function processFrame() {
            //sends the video frame for processing
            pose.send({ image: videoElement });
            //requests the next animation frame (creating a loop that sends frams to pose detector)
            requestAnimationFrame(processFrame);
          }
          //starts the frame processing loop
          processFrame();
        });
      });
    </script>
  </body>
</html>